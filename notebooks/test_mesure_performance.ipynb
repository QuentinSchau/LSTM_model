{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métrique de performance\n",
    "\n",
    "Les métriques de performance permettent de mesurer l'éfficacité de notre modèle. En effet, les courbes ce suffisent pas, un modèle peut avoir des résultats très bon selon une métrique mais très mauvais selon une autre. Il existe plusieurs métrique en fonction du problème considèré. Ici j'ai choisi de vous présenter les métrique les plus utilisées dans le domaine de la régression. \n",
    "\n",
    "Pour l'ensemble des métriques j'utilise la notation suivante :\n",
    "- $y_i$ est la $i^{ème}$ valeur attendue dans l'ensemble de données \n",
    "- $\\hat{y_i}$ est la $i^{ème}$ valeur prédite par notre modèle\n",
    "- $N$ correspond au nombre total de valeur\n",
    "\n",
    "### Mean squared error\n",
    "\n",
    "Mean squared error ou MSE (Le carré Moyen des erreurs) est une mesure d'erreur populaire pour les problèmes de régression.\n",
    "\n",
    "Il s'agit également d'une fonction de perte importante pour les algorithmes ajustés ou optimisés à l'aide du cadrage des moindres carrés d'un problème de régression. L'expression \"moindres carrés\" fait référence à la minimisation de l'erreur quadratique moyenne entre les prédictions et les valeurs attendues.\n",
    "\n",
    "L'MSE est calculée comme la moyenne des différences au carré entre les valeurs cibles prédites et attendues dans un ensemble de données.\n",
    "\n",
    "$MSE = \\frac{1}{N}*\\sum_{n=1}^{N} {(y_i - \\hat{y_i})^2} \\$\n",
    "\n",
    "La différence entre ces deux valeurs est élevée au carré, ce qui a pour effet de supprimer le signe et d'obtenir une valeur d'erreur positive.\n",
    "\n",
    "L'élévation au carré a également pour effet de gonfler ou d'amplifier les erreurs importantes. En d'autres termes, plus la différence entre les valeurs prédites et attendues est grande, plus l'erreur positive au carré qui en résulte est importante. Cela a pour effet de \"punir\" davantage les modèles pour des erreurs plus importantes lorsque le MSE est utilisée comme fonction de perte. Cela a également pour effet de \"punir\" les modèles en gonflant le score d'erreur moyen lorsqu'il est utilisé comme métrique.\n",
    "\n",
    "Le MSE est valeur à minimiser dans le cadre d’une régression simple ou multiple(voir [MSE](http://www.jybaudot.fr/Correl_regress/calcestim.html). La méthode est fondée sur la nullité de la moyenne des résidus. Mais la moyenne de leurs carrés n'est généralement pas nulle. Cette moyenne n'est autre que la variance résiduelle que l'on cherche à minimiser ([Cf. le théorème de König](http://www.jybaudot.fr/Stats/proprvar.html)).\n",
    "\n",
    "\n",
    "### Root Mean Squared Error\n",
    "\n",
    "L'erreur quadratique moyenne, ou RMSE, est une extension de l'erreur quadratique moyenne.\n",
    "\n",
    "Il est important de noter que la racine carrée de l'erreur est calculée, ce qui signifie que les unités de la RMSE sont les mêmes que les unités originales de la valeur cible qui est prédite.\n",
    "\n",
    "Par exemple, si votre variable cible a l'unité \"euro\", le score d'erreur RMSE aura également l'unité \"euro\" et non \"euro au carré\" comme le MSE.\n",
    "\n",
    "Ainsi, il peut être courant d'utiliser la perte MSE pour former un modèle prédictif de régression, et d'utiliser la RMSE pour évaluer et rapporter ses performances. C’est ce que j’ai choisi de faire, j’utilise comme critère le MSE pour l’apprentissage\n",
    "\n",
    "La RMSE peut être calculée comme suit :\n",
    "\n",
    "$RMSE = \\sqrt{\\frac{1}{N}*\\sum_{n=1}^{N} {(y_i - \\hat{y_i})^2}}$\n",
    "\n",
    "Nous pouvons reformuler la RMSE en termes de MSE comme suit :\n",
    "\n",
    "$RMSE = \\sqrt{MSE}$\n",
    "\n",
    "Notez que la RMSE ne peut pas être calculée comme la moyenne de la racine carrée des valeurs de l'erreur quadratique. c'est-à-dire : \n",
    "\n",
    "$RMSE \\neq \\frac{1}{N}*\\sum_{n=1}^{N} {\\sqrt{(y_i - \\hat{y_i})^2}}$\n",
    "\n",
    "Il s'agit d'une erreur courante commise par les débutants et d'un exemple d'inégalité de Jensen.\n",
    "\n",
    "### Mean Absolute Error\n",
    "\n",
    "L'erreur absolue moyenne, ou MAE, est une mesure populaire car, comme la RMSE, les unités du score d'erreur correspondent aux unités de la valeur cible qui est prédite.\n",
    "\n",
    "Contrairement à la RMSE, les variations de la MAE sont linéaires et donc intuitives.\n",
    "\n",
    "C'est-à-dire que la MSE et la RMSE sanctionnent davantage les grandes erreurs que les petites, ce qui gonfle ou amplifie le score d'erreur moyen. Ceci est dû au carré de la valeur de l'erreur. La MAE n'accorde pas plus ou moins de poids aux différents types d'erreurs et, au contraire, les scores augmentent linéairement avec l'augmentation de l'erreur.\n",
    "\n",
    "Comme son nom l'indique, le score MAE est calculé comme la moyenne des valeurs d'erreur absolues. L'erreur absolue ou $|.|$ est une fonction mathématique qui rend simplement un nombre positif. Par conséquent, la différence entre une valeur attendue et une valeur prédite peut être positive ou négative et est forcée d'être positive lors du calcul du MAE.\n",
    "\n",
    "La MAE peut être calculée comme suit :\n",
    "\n",
    "$MAE = \\frac{1}{N}*\\sum_{n=1}^{N} {|y_i - \\hat{y_i}|}$\n",
    "\n",
    "\n",
    "source : \n",
    "- https://en.wikipedia.org/wiki/Mean_squared_error\n",
    "- https://en.wikipedia.org/wiki/Root-mean-square_deviation \n",
    "- https://en.wikipedia.org/wiki/Mean_absolute_error\n",
    "- autre [lien](https://machinelearningmastery.com/regression-metrics-for-machine-learning/#:~:text=Regression%20predictive%20modeling%20are%20those,error%2C%20and%20mean%20absolute%20error).\n",
    "\n",
    "\n",
    "# Evaluation du modèle\n",
    "\n",
    "Pour évaluer notre modèle, nous devons utiliser des données qui non jamais servis lors de l'apprentissage. Ceci permet d'éviter les biais du à un sur-apprentissage.\n",
    "\n",
    "Le modèle se base sur la prédiction temporelle à un pas de temps. C'est-à-dire, nous prédisons seulement la prochaine minute à partir des 5 dernières minutes.\n",
    "\n",
    "On traite les données d'apprentissage avec notamment une normalisation standard pour facilité l'utilisation de notre modèle. Il s'agit des mêmes raisons que lors de l'entrainement. On aura des données de la plage de valeur sera comprise entre 0 et 1.\n",
    "\n",
    "En effet notre modèle c'est entrainé avec des valeurs normées, il nous faut donc retranformer nos données. Ici, j'ai normé les données avec la norme standard:\n",
    "\n",
    "$y = f(x) = \\frac{x - \\mu}{\\sigma}$ où μ représente la moyenne et σ représente l'écart-type\n",
    "\n",
    "la transformation inverse est donc : \n",
    "\n",
    "$f(x) = \\frac{x - \\mu}{\\sigma} = y \\Leftrightarrow x = y*{\\sigma}+\\mu = f^{-1}(y)$\n",
    "\n",
    "Pour tester notre prédiction à un pas de temps, on ne réutilise pas la valeurs prédicte. Considèrons les valeurs $m_i$ comme étant la valeur du bitcoin à la $i^{ème}$ minute. On connais donc les valeurs réelles du bitcoin : $m_1 , m_2, m_3, m_4 , m_5, m_6 ,m_7 ...$\n",
    "\n",
    "- la première prédition $p_1$ utilise les valeurs : $m_1 , m_2 , m_3, m_4, m_5 $\n",
    "- la deuxième prédition $p_2$ utilise donc les valeurs : $m_2 , m_3 , m_4, m_5, m_6 $\n",
    "- la troisème prédition $p_3$ utilise donc les valeurs : $m_3 , m_4 , m_5, m_6, m_7 $\n",
    "\n",
    "On peut essayer faire de la prédiction sur toute la journée (faire de la prédiction à plusieurs pas de temps), cela nous permettera de voir la répercusion des erreurs commisent à chaque minute. Notre modèle n'étant pas concu pour cela, on devrait observer des métriques différentes. \n",
    "\n",
    "Pour tester notre prédiction à plusieurs pas de temps, on réutilise la valeurs prédicte. Considèrons les valeurs $m_i$ comme étant la valeur du bitcoin à la $i^{ème}$ minute. On connais donc les valeurs réelles du bitcoin : $m_1 , m_2, m_3, m_4 , m_5, m_6 ,m_7 ...$\n",
    "\n",
    "- la première prédition $p_1$ utilise les valeurs : $m_1 , m_2 , m_3, m_4, m_5 $\n",
    "- la deuxième prédition $p_2$ utilise donc les valeurs : $m_2 , m_3 , m_4, m_5, p_1 $\n",
    "- la troisème prédition $p_3$ utilise donc les valeurs : $m_3 , m_4 , m_5, p_1, p_2 $\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "from skorch import NeuralNetRegressor\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from skorch.callbacks import LRScheduler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "numFeature = 5\n",
    "\n",
    "model_name = \"20220825_21_51\"\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=200, output_size=1,num_layers=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size,hidden_layer_size,num_layers,batch_first = True)\n",
    "        # linear layer pour préduire \n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        self.hidden_cell = (torch.zeros(1,input_batch.size(0),self.hidden_layer_size,device=input_batch.device),\n",
    "                            torch.zeros(1,input_batch.size(0),self.hidden_layer_size,device=input_batch.device))\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_batch, self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out[:,-1,:])\n",
    "        return predictions\n",
    "     \n",
    "net_regr = NeuralNetRegressor(\n",
    "    LSTM,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    max_epochs=1000,\n",
    "    lr=0.001,\n",
    "    callbacks=[\n",
    "        LRScheduler(policy='StepLR', step_size=100, gamma=0.1)\n",
    "    ],\n",
    "    criterion=nn.MSELoss,\n",
    "    device='cuda' \n",
    ")\n",
    "    \n",
    "print(\"load model\")\n",
    "net_regr.initialize()  # This is important!\n",
    "net_regr.load_params(f_params='../resultat/save_models/'+model_name+'.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui prédit à un pas de temps à partir des valeurs réelles\n",
    "\n",
    "def prediction_un_pas_temps(reel_value,numberData):\n",
    "    \n",
    "    #on a besoin des numFeature première valeur car on va se baser sur elles pour faire la première prédiction\n",
    "    value_predict = reel_value[:numFeature].tolist()\n",
    "    \n",
    "    for index in range(0,numberData-numFeature):\n",
    "        \n",
    "        #sequence to make Tensor for the prediction with the model\n",
    "        prediction_sequence = [[]]\n",
    "        for value in reel_value[index:index+numFeature]:\n",
    "            prediction_sequence[0].append([value])\n",
    "        prediction_vector = torch.FloatTensor(prediction_sequence)\n",
    "        predicted_value = net_regr.predict(prediction_vector).item()\n",
    "        value_predict.append(predicted_value)\n",
    "        \n",
    "    return value_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui prédit à un pas de temps à partir des valeurs réelles\n",
    "\n",
    "def prediction_plusieurs_pas_temps(first_reel_value,numberData):\n",
    "    \n",
    "    #on a besoin des numFeature première valeur car on va se baser sur elles pour faire la première prédiction\n",
    "    value_predict = first_reel_value.tolist()\n",
    "    \n",
    "    for index in range(0,numberData-numFeature):\n",
    "\n",
    "        #sequence to make Tensor for the prediction with the model\n",
    "        prediction_sequence = [[]]\n",
    "        for value in value_predict[index:index+numFeature]:\n",
    "            prediction_sequence[0].append([value])\n",
    "        prediction_vector = torch.FloatTensor(prediction_sequence)\n",
    "        predicted_value = net_regr.predict(prediction_vector).item()\n",
    "        value_predict.append(predicted_value)\n",
    "    return value_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_metrics(reel_value,estimate_value,numberData):\n",
    "    erreurs = reel_value-estimate_value\n",
    "    mse = np.sum(np.power(erreurs,2))/numberData\n",
    "    mae = np.sum(np.abs(erreurs))/numberData\n",
    "    rmse = np.sqrt(mse)\n",
    "    metric = \"Differente métrique pour la prédiction à un pas de temps: \\n\"\n",
    "    metric += \"Le carré moyen des erreurs MSE :\" + str(mse) + \"\\n\"\n",
    "    metric += \"l'erreur moyenne absolue MAE :\" + str(mae) + \"\\n\"\n",
    "    metric += \"L’erreur quadratique moyenne RMSE :\" + str(rmse) + \"\\n\\n\\n\"\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affichage(reel_value,estimate_value,name,metrics):\n",
    "    plt.figure(figsize=(18,12))\n",
    "    plt.title('cours du bitcoin du : '+ name)\n",
    "    plt.ylabel('valeur en euro')\n",
    "    plt.xlabel('durée en minutes')\n",
    "    plt.grid(True)\n",
    "    plt.autoscale(axis='x', tight=True)\n",
    "    plt.plot(reel_value,label=\"valeur réel\")\n",
    "    plt.plot(estimate_value,label=\"valeur prédict\",ls='--')\n",
    "    plt.legend()\n",
    "    plt.figtext(0.11, -0.01, metrics )\n",
    "    plt.savefig('../resultat/predictions/'+name+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retransforme(values,std,mean):\n",
    "    return values * std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui traite le DataFrame, il est subit la normalisation standard\n",
    "# Input : \n",
    "#     - un DataFrame qu'on souhaite normaliser\n",
    "# Output : \n",
    "#     - le DataFrame normaliser\n",
    "#     - la moyenne (ou les moyennes) du DataFrame\n",
    "#     - l'écart-type (ou les écarts-types) du DataFrame\n",
    "def prepross_data(data):\n",
    "    #enlève les valeurs vides\n",
    "    data.dropna(axis=0,inplace=True)\n",
    "    mean = data.mean()\n",
    "    std = data.std()\n",
    "    data =(data-mean)/std\n",
    "    return mean,std,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"../data/test/\")\n",
    "for filename in files:\n",
    "    print(\"\\nTest file : \"+filename)\n",
    "    date_str = filename[10:-4]\n",
    "    filename = \"../data/test/\"+filename\n",
    "    \n",
    "    #clear and prepross data\n",
    "    newData = pd.read_csv(filename,sep=';')\n",
    "    numberData=newData[\"cloture\"].size\n",
    "    print(\"nombre de donnée :\",numberData)\n",
    "\n",
    "    mean,std,newData = prepross_data(newData)\n",
    "    \n",
    "    #add prediction to data frame\n",
    "    newData['valeur_predict_un_pas'] = prediction_un_pas_temps(newData['cloture'].to_numpy(),numberData)\n",
    "    newData['valeur_predict_plusieurs_pas'] = prediction_plusieurs_pas_temps(newData['cloture'][:numFeature].to_numpy(),numberData)\n",
    "    \n",
    "    #retransforme data and display it\n",
    "    newData = retransforme(newData,std[\"cloture\"],mean[\"cloture\"])\n",
    "    \n",
    "    #calcul metrics\n",
    "    metric = calcul_metrics(newData['cloture'].to_numpy(),newData['valeur_predict_un_pas'].to_numpy(),numberData)\n",
    "    affichage(newData['cloture'].to_numpy(),newData['valeur_predict_un_pas'].to_numpy(),\"2022 08 24 avec un pas temps\",metric)\n",
    "    \n",
    "    #calcul metrics\n",
    "    metric = calcul_metrics(newData['cloture'].to_numpy(),newData['valeur_predict_plusieurs_pas'].to_numpy(),numberData)\n",
    "    affichage(newData['cloture'].to_numpy(),newData['valeur_predict_plusieurs_pas'].to_numpy(),\"2022 08 24 plusieurs pas temps\",metric)\n",
    "    \n",
    "    \n",
    "#     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "colab": {
   "collapsed_sections": [],
   "name": "Post_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
